---
---

@string{aps = {American Physical Society,}}

@inproceedings{10.1145/3581791.3596844,
author = {Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei},
title = {Harmony: Heterogeneous Multi-Modal Federated Learning through Disentangled Model Training},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596844},
doi = {10.1145/3581791.3596844},
abstract = {Multi-modal sensing systems are increasingly prevalent in real-world applications such as health monitoring and autonomous driving. Most multi-modal learning approaches need to access users' raw data, which poses significant concerns to users' privacy. Federated learning (FL) provides a privacy-aware distributed learning framework. However, current FL approaches have not addressed the unique challenges of heterogeneous multi-modal FL systems, such as modality heterogeneity and significantly longer training delay. In this paper, we propose Harmony, a new system for heterogeneous multi-modal federated learning. Harmony disentangles the multi-modal network training in a novel two-stage framework, namely modality-wise federated learning and federated fusion learning. By integrating a novel balance-aware resource allocation mechanism in modality-wise FL and exploiting modality biases in federated fusion learning, Harmony improves the model accuracy under non-i.i.d. data distributions and speeds up system convergence. We implemented Harmony on a real-world multi-modal sensor testbed deployed in the homes of 16 elderly subjects for Alzheimer's Disease monitoring. Our evaluation on the testbed and three large-scale public datasets of different applications show that, Harmony outperforms by up to 46.35\% accuracy over state-of-the-art baselines and saves up to 30\% training delay.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {530â€“543},
numpages = {14},
keywords = {modality heterogeneity, balance-aware resource allocation, multi-modal federated learning systems},
location = {Helsinki, Finland},
series = {MobiSys '23}
}

@inproceedings{cheng20_interspeech,
  author={Sitong Cheng and Zhixin Liu and Lantian Li and Zhiyuan Tang and Dong Wang and Thomas Fang Zheng},
  title={{ASR-Free Pronunciation Assessment}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={3047--3051},
  doi={10.21437/Interspeech.2020-2623}
}

@inproceedings{fan2020cn,
  title={Cn-celeb: a challenging chinese speaker recognition dataset},
  author={Fan, Yue and Kang, JW and Li, LT and Li, KC and Chen, HL and Cheng, ST and Zhang, PY and Zhou, ZY and Cai, YQ and Wang, Dong},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={7604--7608},
  year={2020},
  organization={IEEE}
}